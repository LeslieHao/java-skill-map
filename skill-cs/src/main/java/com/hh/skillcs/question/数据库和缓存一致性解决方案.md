### 背景

随着互联网的普及，内容信息越来越复杂，用户数和访问量越来越大，我们的应用需要支撑更多的并发量，同时我们的应用服务器和数据库服务器所做的计算也越来越多。但是往往我们的应用服务器资源是有限的，且技术变革是缓慢的，数据库每秒能接受的请求次数也是有限的（或者文件的读写也是有限的），如何能够有效利用有限的资源来提供尽可能大的吞吐量？一个有效的办法就是引入缓存，打破标准流程，每个环节中请求可以从缓存中直接获取目标数据并返回，从而减少计算量，有效提升响应速度，让有限的资源服务更多的用户。

### Cache Design Pattern

下面所讲的三种缓存模式，其实都是最早在操作系统层、计算机体系结构里设计出的缓存模式，比如CPU的缓存、文件系统的缓存、磁盘的缓存、数据库的缓存等，我们日常开发中在软件层面的缓存模式（mysql+redis）其实就是来源于这些最初的缓存模式（其实我们日常的软件开发过程中的很多东西都是参照操作系统、计算机体系结构的一些设计思路来实现的）

#### 1.Read/Write Through Pattern

<img src="https://tva1.sinaimg.cn/large/007S8ZIlly1gha0dmtszfj30mw05w3yr.jpg" style="zoom:50%;" />

前面Cache Aside 模式中，我们的应用需要维护两个存储，即cache和DB，增加了应用的负担。Read/Write Through 就是把DB和Cache 维护成一个整体，应用只和这个抽象的整体交互。

* Read Through：查询操作时，如果没有命中缓存，则由缓存服务来加载DB然后写入缓存

* Write Through：与Read Through类似，在更新数据时，如果命中了缓存则更新缓存然后同步更新DB，如果没有命中缓存则直接更新数据库然后返回

#### 2.Write Behind Caching Pattern

<img src="https://tva1.sinaimg.cn/large/007S8ZIlly1gha562429fj30ku0580sx.jpg" style="zoom:50%;" />

Write Behind 又叫Wirte Back，Linux 的Page Cache 就是采用这种模式。在更新数据的时候，只更新缓存，不更新数据库而我们的缓存会异步的批量更新数据库。使用这种模式会让I/O操作变得非常快，但是同时也会带来一致性问题，而且可能会丢失数据（Linux 非正常关机会导致数据丢失）。

#### 3.Cache Aside Pattern 旁路缓存模式

<img src="https://tva1.sinaimg.cn/large/007S8ZIlly1gh95l465jyj30j60as0t6.jpg" style="zoom:50%;" />

* hit: 从cache 中读取数据
* not hit: 从cache 中未取到数据，从DB中取到数据，然后放到缓存中
* update: 更新db后，让缓存失效

这是最标准的缓存模式，也是我们软件开发过程中最常使用过的缓存模式。具体为什么不是写数据库后更新缓存，也不是先删除缓存，可以参考Facebook的论文《[Scaling Memcache at Facebook](https://www.usenix.org/system/files/conference/nsdi13/nsdi13-final170_update.pdf)》，主要是为了防止并发写操作造成缓存脏数据

当然，Cache Aside 并不能100%避免问题的出现，只是相对于其他两种策略出现问题的概率更低，Cache Aside出现缓存脏数据的情况只会在查询时缓存失效，而且与写并发，且缓存的写入要发生在写之后。而实际DB的单条读显然是要快于写的，所以这种case出现的概率很低。



<img src="https://tva1.sinaimg.cn/large/007S8ZIlly1gh8tvoe31hj30oo0f8mxy.jpg" style="zoom:50%;" />



<img src="https://tva1.sinaimg.cn/large/007S8ZIlly1gh8ttc1b73j30p80g4mxz.jpg" style="zoom:50%;" />



<img src="https://tva1.sinaimg.cn/large/007S8ZIlly1gh8u124i1kj30os0f8wfa.jpg" style="zoom:50%;" />



### Cache Aside 一致性解决方案

#### 1.延时双删

```java
1.删除缓存
deleteCache();
2.更新db
updateDB();
3.延时MQ(500ms)
delayDeleteCache();
```

<img src="https://tva1.sinaimg.cn/large/007S8ZIlly1gh8tp7wzptj30t60gymy2.jpg" style="zoom:50%;" />

延时双删虽然一定程度上避免了脏数据的出现，但对代码有一定的侵入性，而且极端情况下依然会出现缓存中写入了旧数据，例如在update db 和 del cache 这段时间窗口内发生的读刚好没有命中缓存且刚好write cache 的发生于del cache 之后，则会导致不一致情况的出现。

#### 2.基于binlog优化

基于canal、databus等组件监听binlog，当监听到更新、删除操作发生时，清除缓存中对应的数据，如果缓存清除失败可以进行日志回放（canal 支持）。

<img src="https://tva1.sinaimg.cn/large/007S8ZIlly1gha6qkfsaqj30ps04gaac.jpg" style="zoom:50%;" />

方案2避免了代码入侵，将DB写操作的监听交给了第三方组件去做，但是读写并发时极端情况下依然会出现缓存写入脏数据的情况。

#### 3.缓存操作的有序性

前面我们知道Cache Aside 这种后删除缓存的模式下出现缓存写入脏数据的情况发生于读发生于写之前，但是缓存的写入又发生于写之后，所以要避免这种情况出现的解决方法就是使读写DB之后对缓存的操作是有序的，从而实现DB和缓存的最终一致性。

* 读：如果命中缓存则返回，如果没有命中缓存则去读DB，然后一步的讲data id 写入MQ，消费者消费消息读取数据写入缓存
* 写：先删除缓存，删除之后更新DB，然后通过分析binlog解析出data id（这里直接发MQ 不监听binlog也可以），然后将data id 写入MQ，消费者消费消息清除对应的缓存

<img src="https://tva1.sinaimg.cn/large/007S8ZIlly1gha7u61ivej30tc0gk0tp.jpg" style="zoom:50%;" />

#### 4.终极方案：DB读写串行化

​	我们的应用程序使用数据库时都会维护一个连接池，多个读写操作的工作线程去连接池中获取到不同的连接来对DB进行读写操作，于是读写并发缓存中存入的脏数据

​	那么我们如果能保证对同一data id的读写操作都落到连接池中的同一连接上，这样就能保证对同一数据读写的串行化。

```
// 连接数量
int connectionCount = 100;
// 目标连接id
int targetConnection = id%connectionCount;
// 获取连接 
Connection connection = pool.getConnection(targetConnection);
// 读写操作
connection.update();
```

​	但是，上面只是解决了单一节点下同一数据读写的串行化，集群场景下我们还要想办法让同一数据的操作落在同一个节点上，这就要对负载均衡策略进行一些改造。

```
ServicePool pool = registry.get(serviceName);
// 节点数量
int count = pool.getCount();
// 目标节点id
int target = id%count;
// 获取连接 
Sercice service = pool.getService(targetConnection);
// 读写操作
service.invoke();
```

串行化的解决方案理论上虽然可以实现，但是需要改造连接池、负载均衡策略，同时如果集群中的某个节点宕机，其他节点是否能够立马得到共识，注册中心是否是强一致性，这些都是要面临的问题

#### 参考

[《缓存与数据库一致性保证》](https://mp.weixin.qq.com/s/CY4jntpM7VNkBrz1FKRsOw?)

[《缓存与数据库一致性系列》](https://blog.kido.site/2018/12/08/db-and-cache-03/)

[《缓存的更新套路》](https://coolshell.cn/articles/17416.html)

